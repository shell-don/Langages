#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Author : Mathis PigassouCorrection des Travaux Pratiques :     TP 15 _ variables aléatoires"""import numpy as npimport numpy.random as rdimport matplotlib.pyplot as plt# Exercice 1X = rd.randint(0,4,1000)# Exercice 2Y = rd.randint(0,53,100000)loiDeY = [np.mean(Y==k) for k in range(53)]abscis_2 = [k for k in range(53)]# Plus le nombre de tirage est important plus le graphique sera "plat"# et se rapprochera de la fréquence d'apparition théorique d'une loi uniforme sur # [0,53] ie environ 0.01887# Exercice 3Z = rd.random(100)abscis_3 = np.linspace(-0.5,1.5,100000)fctRepartition = [np.mean(Z<=k) for k in abscis_3]# Exercice 4def attenteNoire():    """    L'experience est une répétition d'un shéma de Bernoulli. Omega = {B,N}**n     avec n un entier naturel avec une probabilité de tiré une boule noire de    1/k*k+1    """    k = 1    while True :        B = rd.binomial(1,1/(k*(k+1)))        if B == 0 :             return k        else :            k += 1N = 20000T = [attenteNoire() for k in range(N)]# estimateur de la moyenne empirique sur N expériences indépendantesprint(np.mean(T))# on sait que X n'admet pas de moment d'ordre 1 (d'éspérence théorique)  car la série # harmonique ne converge pas absoluement. Donc  la loi faible des grands nombre ne# s'applique pas.  Donc la moyenne empirique n'est pas un estimateur convergent de l'espérance.def test_ex_1() -> None :          print(np.mean(X==0))     print(np.mean(X==1))     print(np.mean(X==2))     print(np.mean(X==3))def test_ex_2() -> None :        plt.bar(abscis_2, loiDeY)    plt.show()    def test_ex_3() -> None :        plt.plot(abscis_3, fctRepartition)    plt.show()def test_ex_4() -> None :        abscis = [k for k in range(N)]    ordo = [np.mean(T[:k]) for k in abscis]    plt.plot(abscis, ordo)    plt.show()test_ex_2()